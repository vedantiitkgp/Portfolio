---
date: '2'
title: 'Optimization of LLM inference Accelration Frameworks'
cover: 'EML.jpg'
external: 'https://drive.google.com/file/d/1FRjy9T0VqxjLL1aZaL8Y9QAUQud8hoye/view?usp=sharing'
tech:
  - PyTorch
  - Hugging face
  - Efficent ML
showInProjects: true
---

Leveraged [speculative decoding]() and optimization techniques (quantization, knowledge distillation, pruning) to accelerate autoregressive language model inference, achieving up to 3x speedups while maintaining high output quality, evaluated using ROUGE-1 metrics.